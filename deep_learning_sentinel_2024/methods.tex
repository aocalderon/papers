\section{Desarrollo de la solución}

En esta sección, se presenta un panorama completo del desarrollo de una solución para clasificar cultivos de palma de aceite en Colombia sobre imágenes satelitales de Sentinel 1 y Sentinel 2. Se aborda desde el establecimiento del ambiente de desarrollo y las restricciones técnicas, hasta la construcción detallada del conjunto de datos, incluyendo la selección y procesamiento de imágenes satelitales y su etiquetado. También se describe el enriquecimiento del conjunto de datos mediante técnicas de aumentación y la implementación y validación del modelo de aprendizaje profundo, enfatizando en las estrategias empleadas para garantizar la precisión y efectividad del sistema en la identificación y clasificación de plantaciones de palma aceitera en Colombia.

\subsection{Ambiente de desarrollo, datos y restricciones}
El ambiente de desarrollo consistió en una máquina con sistema operativo Ubuntu, equipada con una tarjeta gráfica de 16 GB de VRAM y 16 GB de RAM. Este entorno fue elegido por su compatibilidad y rendimiento con las herramientas de Deep Learning. Se utilizó Python como lenguaje de programación principal, especialmente con la librería PyTorch para el desarrollo y entrenamiento de los modelos. Las restricciones encontradas incluyeron limitaciones de memoria y tiempo de procesamiento, lo cual fue mitigado mediante técnicas de optimización de modelos y uso eficiente de recursos.

\subsection{Construcción del conjunto de datos}

\subsubsection{Preprocesamiento de Imágenes}
El preprocesamiento de las imágenes de los satélites Sentinel-1 y Sentinel-2 fue un paso crucial en la construcción del conjunto de datos. Este proceso se basó en la adaptación de la composición presentada por Descals et al, (2021). El proceso comenzó con la selección y descarga de imágenes de estos satélites desde Google Earth Engine (GEE).  Para el Sentinel-1, se utilizó el radar de apertura sintética (SAR) en modo Ground Range Detected (GRD), el cual proporciona una resolución temporal de 12 días en órbitas ascendentes y descendentes. Las imágenes utilizadas correspondían a la modalidad de Interferometric Wide Swath, procesadas a una resolución espacial de 10 metros. 

Un aspecto importante del preprocesamiento fue la corrección del ángulo de incidencia local (LIA), que es fundamental para ajustar las imágenes de radar para variaciones topográficas y de orientación. Una vez realizada esta corrección, se calculó el valor mediano de las escenas de radar para la segunda mitad del año 2019, tanto para las órbitas ascendentes como las descendentes. Finalmente, se creó un compuesto final a partir del promedio de estos dos conjuntos de imágenes compuestas, representando tanto las órbitas ascendentes como las descendentes.

Este meticuloso proceso de preprocesamiento de las imágenes de Sentinel-1 y Sentinel-2 fue esencial para asegurar la calidad y la precisión de los datos utilizados en el estudio, permitiendo una representación precisa de las plantaciones de palma aceitera a nivel mundial. se utilizaron específicamente la banda 4 del satélite Sentinel-2 y el radar de apertura sintética (SAR) del Sentinel-1. Para el Sentinel-2, se empleó la banda 4, también conocida como la banda roja, que tiene una longitud de onda central de 665 nm y proporciona datos de reflectancia de la superficie en una resolución de 10 metros. Esta banda fue seleccionada debido a su alta utilidad en la identificación de plantaciones de palma aceitera, particularmente en las plantaciones industriales. La banda 4 destaca por ofrecer un alto contraste en términos de reflectancia entre los caminos dentro de las plantaciones y las áreas circundantes de palma aceitera. Este contraste facilita la identificación de los caminos en las imágenes satelitales, un elemento clave para diferenciar entre plantaciones industriales y de pequeños propietarios. Otro factor que respalda la elección de esta banda es que la dispersión de luz alta en el espectro del infrarrojo cercano hace que la identificación de caminos sea menos factible en otras bandas, como la banda 8 que también opera en el infrarrojo cercano.

Por otro lado, para el Sentinel-1, se utilizó el modo Ground Range Detected (GRD) del radar de apertura sintética (SAR). Este modo se procesó en la modalidad de Interferometric Wide Swath, con una resolución espacial de 10 metros. Los datos del Sentinel-1, que trabajan en la banda C del espectro de microondas, son especialmente valiosos para la detección y clasificación de características en la superficie terrestre, incluyendo la vegetación. Este modo de radar es capaz de proporcionar datos confiables independientemente de las condiciones climáticas o la luz del día, lo que lo hace muy útil para el monitoreo constante de áreas extensas como las plantaciones de palma aceitera.  Además, los datos de Sentinel-1 fueron procesados con una corrección del ángulo de incidencia local (LIA), y se calculó el valor mediano para las escenas ascendentes y descendentes por separado durante la segunda mitad de 2019, creando así un compuesto final a partir del promedio de estas dos órbitas.

\subsubsection{Etiquetado de Imágenes}
El proceso de etiquetado de imágenes fue un paso crucial para el entrenamiento y la predicción utilizando modelos de segmentación semántica. Este proceso implicó varios pasos detallados a continuación:

\begin{itemize}
    \item \textit{Establecimiento del Tamaño de las Imágenes:} Las imágenes utilizadas para el etiquetado y el entrenamiento del modelo necesitaban tener un tamaño constante. Siguiendo el trabajo realizado por Descals et al. (2021), se estableció un tamaño de imagen de entrada de 1000 x 1000 píxeles. Este tamaño corresponde a un área de 10 x 10 km en una imagen con una resolución de 10 metros.
    
    \item \textit{Selección de Imágenes de Satélite:} Para el etiquetado, se utilizaron la composición que se describe en el preprocesamiento en un periodo de tiempo semestral de Sentinel-1 y Sentinel-2.
    
    \item \textit{Etiquetado:} Para el etiquetado de las imágenes se usaron los datos de Descals et al. (2021) en las zonas seleccionadas. Adicionalmente, se cambiaron las máscaras de etiquetado de pequeños agricultores y los industriales a un solo tipo de categoría.
\end{itemize}

\subsubsection{Aumento de Datos}
El proceso de aumento de datos se centró en generar un conjunto de datos de entrenamiento más diverso a partir del conjunto original. Esta técnica es especialmente útil cuando el tamaño del conjunto de datos de entrenamiento es limitado. En el caso de este estudio, se aplicaron transformaciones afines a los datos de entrenamiento originales. La técnica específica utilizada fue la rotación de imágenes. Se rotaron las imágenes 90 grados en el sentido de las agujas del reloj.

El uso de transformaciones afines como la rotación es una práctica común en estudios de teledetección y aprendizaje profundo. Estas técnicas han demostrado mejorar la precisión de los modelos de aprendizaje profundo, ya que ayudan a crear un conjunto de datos de entrenamiento que representa de manera más efectiva la variabilidad y las diferentes orientaciones que pueden encontrarse en imágenes reales.

\subsection{Implementación del modelo}
El modelo en cuestión acepta como entrada imágenes en formato PNG. La salida generada por el modelo son igualmente imágenes en formato PNG, con una resolución de 1000x1000 píxeles. Tras la generación de la salida, se procede a la creación de una imagen en formato TIFF. Esta imagen se caracteriza por incorporar georreferenciación y una máscara de salida proporcionada por el modelo. Para la implementación de la arquitectura DeepLabV3+, inicialmente propuesta por Chen et al. (2018), se ha optado por el uso de la biblioteca segmentation\_models.pytorch de PyTorch. El modelo se configuró utilizando el encoder timm-mobilenetv3\_large\_100, el cual fue preentrenado con el dataset ImageNet. Dado el objetivo del modelo de clasificar la presencia o ausencia de palma de aceite, se establecieron dos clases y se optó por la función de activación sigmoid. La función de pérdida seleccionada fue la Entropía Cruzada Binaria (Binary Cross Entropy - BCE), considerada idónea para tareas de clasificación binaria.

El entrenamiento del modelo se desarrolló a lo largo de 20 épocas. Durante cada época, se evaluaron y registraron las métricas especificadas en la sección 6.4.1. Se procedió a guardar el modelo que demostraba el mejor rendimiento en cada instancia. Se definió un tamaño de lote (batch size) de 7, optimizando el uso de los recursos computacionales disponibles. El conjunto de datos empleado para el entrenamiento y la validación del modelo consistió en 270 imágenes. De estas, el 70\% (189 imágenes) se asignaron al conjunto de entrenamiento y el 30\% restante (81 imágenes) al conjunto de validación, asegurando así una distribución equilibrada de los datos, lo que facilitó un entrenamiento eficiente y una validación precisa del modelo.

\subsection{Validación del modelo}

\subsubsection{Métricas}
Para una evaluación integral y precisa del modelo, se seleccionaron cuatro métricas clave: precisión (accuracy), sensibilidad (recall), precisión (precision) y la puntuación F1 (f1-score). Cada una de estas métricas aporta una perspectiva única en la evaluación del modelo, permitiendo un análisis exhaustivo de su rendimiento. La combinación de estas métricas proporciona una visión holística y equilibrada del rendimiento del modelo, asegurando no solo su capacidad para clasificar con exactitud, sino también su eficiencia en la identificación de casos relevantes y la minimización de falsos positivos.

\subsection{Validación de los resultados}
Para la validación del modelo, se seleccionaron específicamente varias zonas dentro del territorio colombiano. Estas áreas fueron elegidas en función de su relevancia agrícola y la presencia diversificada de cultivos, incluyendo, de manera prominente, plantaciones de palma de aceite. La elección de estas zonas permite una evaluación efectiva del modelo en diferentes escenarios y condiciones ambientales, lo cual es crucial para asegurar su robustez y adaptabilidad. Como parte del proceso de validación, se realizaron evaluaciones visuales utilizando el software QGIS \cite{QGIS_software}. Esta herramienta de Sistemas de Información Geográfica (SIG) permitió una inspección detallada y minuciosa de las predicciones realizadas por el modelo sobre los diferentes cultivos. La evaluación visual en QGIS implicó la comparación de las imágenes de salida del modelo con las imágenes satelitales reales y los datos existentes sobre la ubicación y extensión de los cultivos en las zonas de estudio. Este enfoque permitió identificar no solo la precisión general del modelo, sino también comprender mejor sus limitaciones y áreas de mejora potencial, como la diferenciación entre tipos de cultivo y la precisión en la detección de los límites de las plantaciones.
