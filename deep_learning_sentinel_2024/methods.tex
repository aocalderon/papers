\section{Desarrollo de la solución}

En esta sección se presenta un panorama completo del desarrollo de una solución para clasificar cultivos de palma de aceite en Colombia utilizando imágenes satelitales de Sentinel-1 y Sentinel-2. El proceso abarca desde el establecimiento del ambiente de desarrollo y las restricciones técnicas, hasta la construcción detallada del conjunto de datos, incluyendo la selección, el procesamiento de imágenes satelitales y su etiquetado. Asimismo, se describe el enriquecimiento del conjunto de datos mediante técnicas de aumentación, junto con la implementación y validación del modelo de aprendizaje profundo. Se enfatizan las estrategias empleadas para garantizar la precisión y efectividad del sistema en la identificación y clasificación de plantaciones de palma aceitera en Colombia.

\subsection{Ambiente de desarrollo, datos y restricciones}

El ambiente de desarrollo consistió en una máquina con sistema operativo Ubuntu, equipada con una tarjeta gráfica de 16 GB de VRAM y 16 GB de RAM. Este entorno fue seleccionado por su compatibilidad y rendimiento con herramientas de Deep Learning. Se utilizó Python como lenguaje de programación principal, junto con la librería PyTorch para el desarrollo y entrenamiento de los modelos. Entre las restricciones identificadas se encontraron limitaciones de memoria y tiempo de procesamiento, las cuales fueron mitigadas mediante técnicas de optimización de modelos y un uso eficiente de los recursos.

\subsection{Construcción del conjunto de datos}

\subsubsection{Preprocesamiento de Imágenes}

El preprocesamiento de las imágenes de los satélites Sentinel-1 y Sentinel-2 fue un paso crucial en la construcción del conjunto de datos, basado en la adaptación de la composición presentada por \cite{descals2021}. El proceso comenzó con la selección y descarga de imágenes desde Google Earth Engine (GEE). Para el Sentinel-1, se empleó el radar de apertura sintética (SAR) en modo Ground Range Detected (GRD), que ofrece una resolución temporal de 12 días en órbitas ascendentes y descendentes. Las imágenes correspondían a la modalidad de Interferometric Wide Swath y fueron procesadas a una resolución espacial de 10 metros. 

Un aspecto clave del preprocesamiento fue la corrección del ángulo de incidencia local (LIA), esencial para ajustar las imágenes de radar ante variaciones topográficas y de orientación. Tras realizar esta corrección, se calculó el valor mediano de las escenas de radar para la segunda mitad del año 2019, tanto para las órbitas ascendentes como descendentes. Finalmente, se generó un compuesto final promediando estos dos conjuntos de imágenes, representando ambas órbitas.

Este meticuloso preprocesamiento fue esencial para garantizar la calidad y precisión de los datos utilizados, asegurando una representación adecuada de las plantaciones de palma aceitera. Para el Sentinel-2, se utilizó específicamente la banda 4, conocida como la banda roja, con una longitud de onda central de 665 nm y una resolución espacial de 10 metros. Esta banda fue seleccionada por su alta utilidad en la identificación de plantaciones de palma aceitera, especialmente en plantaciones industriales. Su capacidad para ofrecer un alto contraste en la reflectancia entre los caminos dentro de las plantaciones y las áreas circundantes facilita la identificación de los caminos, un elemento crucial para diferenciar plantaciones industriales de pequeños propietarios. La elección de esta banda se debe también a que, en el espectro del infrarrojo cercano, la dispersión de luz alta dificulta la identificación de caminos en otras bandas, como la banda 8.

Por otro lado, para el Sentinel-1 se utilizó el modo Ground Range Detected (GRD) del radar de apertura sintética (SAR), procesado en la modalidad de Interferometric Wide Swath con una resolución espacial de 10 metros. Los datos del Sentinel-1, que operan en la banda C del espectro de microondas, son especialmente valiosos para detectar y clasificar características de la superficie terrestre, incluida la vegetación. Este radar proporciona datos confiables independientemente de las condiciones climáticas o de la iluminación, lo que lo hace ideal para monitorear extensas áreas de plantaciones de palma aceitera. Además, los datos de Sentinel-1 fueron procesados aplicando una corrección del ángulo de incidencia local (LIA), y se calculó el valor mediano de las escenas ascendentes y descendentes de la segunda mitad de 2019. Finalmente, se generó un compuesto final promediando ambas órbitas.

\subsubsection{Etiquetado de Imágenes}

El proceso de etiquetado de imágenes fue un paso fundamental para el entrenamiento y la predicción utilizando modelos de segmentación semántica. Este proceso incluyó varias etapas, detalladas a continuación:

\begin{itemize} 

    \item \textit{Establecimiento del Tamaño de las Imágenes:} Las imágenes utilizadas para el etiquetado y el entrenamiento del modelo debían tener un tamaño uniforme. Basándose en el trabajo de \cite{descals2021}, se definió un tamaño de entrada de 1000 x 1000 píxeles, correspondiente a un área de 10 x 10 km en imágenes con una resolución de 10 metros.

    \item \textit{Selección de Imágenes de Satélite:} Para el etiquetado, se utilizó la composición descrita en la etapa de preprocesamiento, correspondiente a un periodo semestral de imágenes de Sentinel-1 y Sentinel-2.

    \item \textit{Etiquetado:} El etiquetado de las imágenes se realizó utilizando los datos proporcionados por \cite{descals2021} en las zonas seleccionadas. Además, las máscaras de etiquetado de pequeños agricultores e industriales se unificaron en una única categoría.

\end{itemize}

\subsubsection{Aumento de Datos}

El proceso de aumento de datos se enfocó en generar un conjunto de datos de entrenamiento más diverso a partir del conjunto original, una técnica especialmente útil cuando el tamaño del conjunto de datos de entrenamiento es limitado. En este estudio, se aplicaron transformaciones afines a los datos de entrenamiento originales, específicamente la rotación de imágenes. Las imágenes fueron rotadas 90 grados en el sentido de las agujas del reloj.

El uso de transformaciones afines como la rotación es una práctica común en estudios de teledetección y aprendizaje profundo. Estas técnicas han demostrado mejorar la precisión de los modelos al crear un conjunto de datos de entrenamiento que representa de manera más efectiva la variabilidad y las diferentes orientaciones que pueden encontrarse en imágenes reales.

\subsection{Implementación del modelo}

El modelo acepta como entrada imágenes en formato PNG y genera salidas en el mismo formato, con una resolución de 1000x1000 píxeles. Posteriormente, estas salidas se convierten en imágenes en formato TIFF, incorporando georreferenciación y una máscara de salida proporcionada por el modelo. Para implementar la arquitectura DeepLabV3+, propuesta originalmente por \cite{chen2018}, se utilizó la biblioteca \texttt{segmentation\_models} de PyTorch. El modelo fue configurado con el codificador \texttt{timm-mobilenetv3\_large\_100}, preentrenado con el conjunto de datos ImageNet. Dado que el objetivo del modelo era clasificar la presencia o ausencia de palma de aceite, se definieron dos clases y se empleó la función de activación \textit{sigmoid}. La función de pérdida seleccionada fue la Entropía Cruzada Binaria (\textit{Binary Cross Entropy} - BCE), ideal para tareas de clasificación binaria.

El entrenamiento del modelo se llevó a cabo durante 20 épocas, evaluando y registrando las métricas especificadas en la sección 6.4.1 en cada iteración. Se guardó el modelo con el mejor rendimiento en cada época. El tamaño de lote (\textit{batch size}) se estableció en 7, optimizando el uso de los recursos computacionales disponibles. El conjunto de datos utilizado para el entrenamiento y la validación del modelo incluyó 270 imágenes, de las cuales el 70\% (189 imágenes) se asignaron al conjunto de entrenamiento, mientras que el 30\% restante (81 imágenes) se destinaron al conjunto de validación. Esta distribución equilibrada garantizó un entrenamiento eficiente y una validación precisa del modelo.

\subsection{Validación del modelo}

\subsubsection{Métricas}

Para garantizar una evaluación integral y precisa del modelo, se seleccionaron cuatro métricas clave: precisión (\textit{accuracy}), sensibilidad (\textit{recall}), precisión (\textit{precision}) y la puntuación F1 (\textit{f1-score}). Cada una de estas métricas ofrece una perspectiva única para analizar el rendimiento del modelo. Su combinación proporciona una visión holística y equilibrada, evaluando no solo la capacidad del modelo para clasificar con exactitud, sino también su eficiencia en identificar casos relevantes y minimizar falsos positivos.

\subsection{Validación de los resultados}

Para validar el modelo, se seleccionaron varias zonas dentro del territorio colombiano, elegidas por su relevancia agrícola y la diversidad de cultivos presentes, incluyendo, de manera prominente, plantaciones de palma de aceite. Esta selección permitió evaluar de manera efectiva el rendimiento del modelo en diferentes escenarios y condiciones ambientales, lo cual es esencial para asegurar su robustez y adaptabilidad.

Como parte del proceso de validación, se realizaron evaluaciones visuales utilizando el software QGIS \cite{QGIS_software}. Esta herramienta de Sistemas de Información Geográfica (SIG) permitió inspeccionar detalladamente las predicciones del modelo sobre los cultivos analizados. La evaluación visual en QGIS consistió en comparar las imágenes generadas por el modelo con las imágenes satelitales originales y los datos existentes sobre la ubicación y extensión de los cultivos en las zonas de estudio. Este enfoque no solo permitió medir la precisión general del modelo, sino también identificar sus limitaciones y áreas de mejora potencial, como la diferenciación entre tipos de cultivo y la precisión en la detección de los límites de las plantaciones.
